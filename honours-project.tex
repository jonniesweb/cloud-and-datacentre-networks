\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{nameref,csquotes,hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
    citecolor=blue,
    pdftitle={Cloud and Datacentre Networks},
}
\usepackage[english]{babel}
\usepackage[backend=biber,style=numeric]{biblatex}
\urlstyle{sf}

\usepackage{enumitem}
\setlist{nolistsep}


\bibliography{research}

\newcommand{\secref}[1]{Section \ref{#1} - \emph{\nameref{#1}}}


\iffalse
 % Outline
1. clouds (services)
2. network structure (data centre network)
3. SDN
4. data processing
5. Hadoop
6. security
7. user concerns
 - fairness
 - budget
 - deadline
 - other constraints?
8. provider concerns
 - resource management
 - energy efficiency


\fi



\title{Cloud and Datacentre Networks}
\author{Jon Simpson}
\date{Fall 2016}


\begin{document}
\pagenumbering{roman}

\maketitle
\thispagestyle{empty}

\begin{abstract}
    Foo
\end{abstract}
\newpage

\tableofcontents

\pagenumbering{arabic}

\section{Introduction} \label{sec:introduction}

Cloud and datacentres are becoming larger and more advanced in the race to provide competitive services to customers. Cloud computing demand keeps increasing as businesses find that it's more affordable to have other companies manage their infrastructure. Current datacentres are continually improving their systems to make each joule of energy as efficient as possible. The distributed systems running atop these massive clusters requires high bandwidth, low-latency networks across the nodes of a cluster. Being able to optimize globally across the cloud or datacentre by a small percentage can result in large savings.

In this paper, the main topics of cloud and datacentre networking are explained with the most up to date information available.


% reference google networking paper with 100-fold increase in speed

\subsection{Contribution} \label{sub:contribution}

\subsection{Methodology} \label{sub:methodology}

% update section names
This article is a meta-survey, constructed from a number of recent surveys and new articles focused on the topics of cloud services, network structures, software defined networks, data processing, Hadoop, security and scheduling. The main points and ideas are collected and explained then compared for their commonalities and differences. The information collected from the surveys are updated with newer articles that have come out since their respective publishing date.

% end subsection methodology
\subsection{Paper Organization} \label{sub:organization}

% update organization with updated sections

Cloud and datacentre networking is broken down into the following seven sections:
\secref{sec:cloud-services} breaks down the different types of services offered by cloud providers, \secref{sec:network-structure} shows different strategies of defining the physical structure of the datacentre network, \secref{sec:sdn} discusses the virtual networking abstractions that can be built on top of the physical networks, \secref{sec:data-processing} is where batch and stream processing of data is explained, \secref{sec:hadoop} being one of the leading big data processing frameworks, \secref{sec:security} for the importance and new attack vectors for modern cloud and datacentre infrastructures, and lastly \secref{sec:scheduling} discusses and classifies the algorithms and workload characteristics that go in to assigning resources to workloads.

\subsection{Resources} \label{sub:resources}

At the bottom layer of every datacentre and cloud is the individual resources that power it. Single units of resources that when interconnected together form powerful networks of compute and storage. The compute, network and storage resources require a comparably sized power grid to keep all of the components powered.

\subsubsection{Compute} \label{ssub:compute}

Compute is the main resource consisting of memory, CPU, network interface and local I/O. Many times the service provider runs virtual machines on top of the physical machines for the consumers to use. This provides a necessary level of abstraction to separate users in a cloud computing environment \cite{Jennings2015}.

% subsubsection compute (end)
\subsubsection{Network} \label{ssub:network}

Network equipment interconnect the computing resources to allow for high speed communication between other compute resources and the internet. Communicating effectively is constrained by cost \cite{Jennings2015}. A complete graph connects every compute resource to every other compute resource but the cost of each link grows by $n$, where $n$ is the number of compute resources, also known as nodes.

The goal of interconnecting compute resources is to provide a scalable topology where ``increasing the number of ports in the network should linearly increase the bisection bandwidth'' \cite{abts2012guided}.

The most commonly used topology for datacentres is trees. Trees provide a high bisection bandwidth for all nodes connected to the same switch. Also well known is the hyper-cubes and meshes, which are more present in High Performance Computing (HPC) \cite{Jennings2015}. Another type of topology is the Clos network. % go into more detail

Software Defined Networks (SDN) is making it possible to have more flexible networks. Custom protocols and different addressing schemes can be used where a physical network would be impractical otherwise.

% subsubsection network (end)
\subsubsection{Storage} \label{ssub:storage}


% this paragraph is awkward
Public cloud providers currently offer persistent storage through virtual disks, object storage and various types of databases. Common databases that are available are of the ACID type, while a newer type of database is of the NoSQL type. These newer types of databases are more scalable but less consistent since they don't follow the ACID transactional properties. The trade-off with these two different types of databases is performance and consistency, where performance caters to availability and response time, and consistency follows the ACID transactional properties \cite{Jennings2015}.

These NoSQL database systems do well for many use cases which don't require strong consistency. A few different types available are column stores, key-value stores, document stores, and graph databases \cite{graphDB2013}. Object stores are built on top of key-value stores, where a key is used to retrieve some data or new data is uploaded and a key corresponding to that data is returned. Both Amazon \cite{dynamodb}, Google \cite{cassandra} and LinkedIn \cite{voldemort} have their own version of a key-value datastore.

% subsubsection storage (end)

\subsubsection{Power} \label{ssub:power}

Datacentres use a significant amount of the world's energy. Powering the networking, compute and storage systems as well as the ancillary systems such as cooling, power distribution and lighting.
There are four main ways to reduce power consumption for datacentres as defined by Jennings \cite{Jennings2015}. Those are: creation of lower-power usage devices for hardware energy efficiency, energy-aware resource management (see section \ref{provider-concerns} for more information), designing applications with awareness of it's energy use, and development of more efficient ancillary systems. Additionally, the climate of the location of a datacentre can aid greatly in cooling systems \cite{norwaydatacentre}.

% subsubsection power (end)

% end subsection Resources
\section{Cloud Services} \label{sec:cloud-services}

The definition of cloud services (also known as cloud computing) is best described by the National Institute of Standards and Technology (NIST):

\begin{displayquote}
Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. This cloud model is composed of five essential characteristics, three service models, and four deployment models \cite{mell2011nist}.
\end{displayquote}

In the next three sections the essential characteristics, service models, and deployment models are explained.


% future subsection: taxonomy (2009) - cloud architecture, virtualization management, service (iaas,paas, etc), fault tolerance, security

\subsection{Essential Characteristics} \label{sub:essential-characteristics}
% Essential characteristics - on-demand self service, broad network access, resource pooling, rapid elasticity, measured service

Cloud computing can be characterized by the five distinct characteristics that separate it from traditional computing. Those five characteristics are on-demand self service, broad network access, resource pooling, rapid elasticity, and measured service \cite{alam2015comprehensive, dillon2010cloud}.

\subsubsection{On-Demand Self Service} \label{ssub:on-demand}

Consumers are able to request and receive computing resources at any time from the service provider without having to interact with a human. This means that humans and other systems are able to automatically obtain and release computing resources depending on their needs.


% subsubsection on-demand (end)
\subsubsection{Broad Network Access} \label{ssub:net-access}

Customers of the consumer are able to access and interact with the computing resources over a network, such as the Internet. Heterogeneous customers are all able to access the resources if they are able to access the network.


% subsubsection net-access (end)
\subsubsection{Resource Pooling} \label{ssub:resource-pooling}

Resources of the provider are pooled together such that the consumer is unaware of the underlying organization of the physical hardware. The resource pooling is achieved either through multi-tenancy or virtualization of the computing resources. This enables flexibility for the provider as they are able to flexibly grow or shrink their physical infrastructure without affecting the consumer's resource allocations. Consumers also benefit by being able to dynamically change their resource allocations and not have to worry about the placement of those resources.


% subsubsection resource-pooling (end)
\subsubsection{Rapid Elasticity} \label{ssub:elasticity}

Consumers of the cloud service are able to change their resource allocation at any time without any prior commitment or contracts. The maximum amount of resources that can be allocated should appear to be infinite to the consumer. Consumers are freely able to scale up and scale down resource allocation according to their needs.


% subsubsection elasticity (end)
\subsubsection{Measured Service} \label{ssub:measured-service}

Pooled resources that are shared among many consumers (possibly multiple consumers sharing the same physical hardware) are able to be measured by other cloud infrastructure. The provider may simply track it for driving business decisions or additionally use this information to bill the consumer.


% subsubsection measured-service (end)

% subsection essential-characteristics (end)
\subsection{Service Models} \label{sub:servicemodels}

Cloud services can be broadly categorized into three major categories:\linebreak Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS), and\linebreak Software-as-a-Service (SaaS). Buying IaaS from a provider gives the customer the ability to not have to worry about managing the physical infrastructure. All the cloud resources that they deal with is virtualized. In PaaS, customers use and build software on top of the providers platform. The use case solved by the platform is to make it easier and faster to build scalable software without having to worry about the underlying infrastructure. SaaS is a cloud classification where the provider manages the software, it's associated data and the infrastructure it uses on behalf of the customer. The customer benefits by being able to use the service without having to deal with running and maintaining the infrastructure \cite{Manvi2014}.

\subsubsection{Infrastructure as a Service} \label{ssub:iaas}

IaaS utilizes virtualization of the hardware to make the on-demand creation, configuration and removal of computing, storage and network equipment faster than the same process using physical hardware. The providers of IaaS are able to rent their virtualized hardware to customers as needed. Basic services such as server images, storage, and resource information are provided by the IaaS provider to make management simpler for customers.

% subsubsection iaas (end)
\subsubsection{Platform as a Service} \label{ssub:paas}

PaaS builds on top of IaaS by giving the customer the ability to build and run applications on top of a platform provided by the cloud provider. PaaS leaves the management of infrastructure up to the provider, leaving the customer to only worry about their application. PaaS usually have their support multiple programming languages and provide a Source Development Kit (SDK) to customers for building their apps. A management console may be provided to manage resources, configure PaaS services and view operational information. Notable companies in this space are Heroku \cite{heroku} and Google App Engine \cite{googleappengine}.

% subsubsection paas (end)
\subsubsection{Software as a Service} \label{ssub:saas}

SaaS is a piece of software that is hosted by the provider and accessed over a network by the customer. SaaS reduces the need for the customer to maintain the hardware and software required to run the software product since the provider takes care of that. General pricing models for SaaS applications follow usage per month or per-user per month. Other types of SaaS have emerged from the expanding functionality of websites. Many websites may offer feature-rich services through the user's web browser. Examples of SaaS include various social networks \cite{facebook}, business applications \cite{salesforce} and interactive websites \cite{netflix}.

% subsubsection saas (end)


% subsection servicemodels (end)
\subsection{Deployment Models} \label{sub:deployment-model}
% deployment model - public,private, community, hybrid

Orthogonal to the \nameref{sub:servicemodels} section is the deployment model. Different types of cloud services can be deployed in different scenarios based on policy, ownership, cost, and security. To the customer of the consumer, the deployment model of the cloud service is completely transparent.

\subsubsection{Public} \label{ssub:deploy-public}

The most prominent type of cloud deployment is the public cloud. Public clouds enable any person or organization to use computing resources. The cloud provider is usually an organization which in charge of the cloud's availability, policies, billing models and operation.


% subsubsection deploy-public (end)
\subsubsection{Private} \label{ssub:deploy-private}

Many different types of organizations would consider to run a private cloud. These clouds are either operated by the organization or a third party on behalf of the organization. Organizations and enterprises run their own private cloud if they have sensitive data or mission critical services that require full control over the entire computing stack, to maximize the utilization of their current computing resources, or if it's not economical to send large amounts of data off premise to a computing provider. Additionally, researchers may also build their own for their research and teaching.


% subsubsection deploy-private (end)
\subsubsection{Community} \label{ssub:deploy-community}

A group of organizations contribute to the building and management of a cloud infrastructure. Policies and other rules are decided by the group. Each organization would get a proportion of the computing resources according to their agreement. The cloud could be hosted remotely or in the premises of one of the organizations.



% subsubsection deploy-community (end)
\subsubsection{Hybrid} \label{ssub:deploy-hybrid}

Public-private, private-community, public-community, and public-private-community are all combinations of hybrid clouds. Hybrid clouds require the ability to seamlessly move workloads and data from one cloud to another. If free computing resources is reaching it's maximum on a private cloud, a public cloud can be used to provide extra resources. This is called ``cloud bursting'' as it can provide extra computing resources when the organization's own computing resources are in peak demand \cite{dillon2010cloud}.


% subsubsection deploy-hybrid (end)

% subsection deployment-model (end)

% section cloud-services (end)
\section{Network Structure} \label{sec:network-structure}

Cloud and datacentres require an interconnect for servers to communicate with each other and for providing service to consumers on the Internet. Many different types of structures are possible but all offer their benefits and weaknesses. Described next are the features of network topologies, then the different network topology types themselves.


\subsection{Topology Features} \label{sub:topology-features}

Network topologies come in many different shapes and sizes. Based on the cloud or datacentre's use cases and the organization's budget some topologies are better than others. The following features break down the different network structures available. Those features are: parallel traffic, bandwidth oversubscription, backwards capability, scalability, automatic renaming, robustness, and load balance \cite{wang2015survey}.


\subsubsection{Parallel Traffic} \label{ssub:parallel-traffic}

Workloads which require different types of communication such as one-to-all, one-to-many, or all-to-all should be taken into consideration as the bandwidth required for these communication styles can be high depending on the number of servers processing the workload. An example of the all-to-all communication style would be the Hadoop MapReduce shuffle phase, where data is transferred from the map task running on many servers to the reduce stage which also runs on many servers.

% subsubsection parallel-traffic (end)
\subsubsection{Bandwidth Oversubscription} \label{ssub:bandwidth-oversubscription}

The more servers that are connected with each other the more expensive it is to provide a full bisection bandwidth. Topology design then cost are the main drivers of bisection bandwidth.  Bandwidth oversubscription occurs when the network topology doesn't provide full bandwidth bisection. The oversubscription can be expressed as a ratio for quantitative comparison. Some providers may choose a topology which performs bandwidth oversubscription on the premise that the network bandwidth will not be the bottleneck resource.


% subsubsection bandwidth-oversubscription (end)
\subsubsection{Backwards Capability} \label{ssub:backwards-capability}

The ability to communicate in one direction should be possible and as performant in the other direction as well. An example would be workloads which require two servers being able to use their full bisection bandwidth in both directions to communicate with each other.


% subsubsection backwards-capability (end)
\subsubsection{Scalability} \label{ssub:net-scalability}

As cloud and datacentre computing demand grows, so does the ability to scale existing computing resources and the networks that interconnect them. The ease at which adding on or removing from an existing network is defined as the scalability. Two important factors with scaling is the ability to interconnect servers on the order of thousands together, as well as the possibility of expanding the network size in the future without requiring substantial reorganization of the existing network.


% subsubsection net-scalability (end)
\subsubsection{Automatic Renaming} \label{ssub:auto-renaming}

Each switch and node in the network should automatically be able to determine where it is and setup its routing table respective to its adjacent nodes, whether that is other servers or switches. This is opposite to offline configuration, where a human or program configures the routing information for each switch and node in the network.


% subsubsection auto-renaming (end)
\subsubsection{Robustness} \label{ssub:net-robustness}

A topology should provide a way to route traffic around a failed switch or link. The more robust a network topology is the more failure it can tolerate before part of it becomes unavailable. Redundant paths in the network increase the robustness by providing an additional way for communication to occur between servers in the network.


% subsubsection net-robustness (end)
\subsubsection{Load Balance} \label{ssub:net-load-balance}

The design of the topology should take into account where bottlenecks could occur because this could lead to performance problems such as congestion. Congestion can occur at the bottleneck from too much data being sent in to the switch and there being not enough bandwidth to send back out. The switch would either slow down the consumption of incoming data or drop input data entirely. The result of congestion is increased latency and communication timeouts. In workloads with high data exchange it may be important to have a stable latency in presence of high bandwidth usage across the network.


% subsubsection net-load-balance (end)

% subsection topology-features (end)


\subsection{Hierarchical Model} \label{sub:net-hierarchical}

Hierarchical models are the most commonly used since they offer simple deployment and straightforward comprehension of the multiple layers that comprise it \cite{wang2015survey, xia2016survey}. Each layer in a hierarchical network treats traffic differently. Congestion is reduced from the lower layers by sending data through the upper layers, which are better suited to route traffic from point-to-point. Described here are three-tier \cite{kliazovich2012greencloud}, Fat-tree \cite{al2008scalable}, and VL2 \cite{greenberg2009vl2}.

\subsubsection{Three-tier} \label{subp:three-tier}

One of the most common hierarchical models is the three-tier hierarchical topology. It consists of the core, aggregation and edge layers, where the edge layer is the layer directly connected to the servers (also known as the top of rack switch (ToR)), the aggregation layer which interfaces between the edge layer and the core layer, and the core layer directly connects to the Internet as well as to every aggregation layer. This layout enables the addition or removal of edge switches and aggregation switches with the minimal amount of modification to the existing network.
% subsubsection three-tier (end)

\subsubsection{Fat-tree} \label{subp:fat-tree}

The Fat-tree hierarchical network structure takes the existing three-tier topology and groups together aggregated switches with it's associated edge switches to form pods. These pods are then connected to the core layer switches for performing communication between the Internet and the pods. All switches in all three layers are identical commodity switches. At each higher layer the number of switches increases to provide full end-to-end bisection bandwidth. Another benefit is that there exists multiple equal-cost paths for communication to occur between any two hosts. The downside to Fat-trees is that the cabling complexity is large due to obtaining the full bisection bandwidth.
% subsubsection fat-tree (end)

% VL2
\subsubsection{VL2} \label{subp:vl2}

VL2 is a creation by Microsoft which performs addressing using two addresses: one called the Location-specific IP address (LA), and the other being the Application-specific IP address (AA). The LA is used by the switches to forward the packet to the proper machine while the AA is encapsulated in the LA header and provides a never changing address to the application or VM that should receive the packet. This split address design allows the application to change the physical machines that it runs on while still retaining the same AA, thereby supporting application or VM migrations. The underlying network routes the AA to the proper LA. Once a packet egresses the edge router it is encapsulated with a LA header. When a packet ingresses the edge router the LA header is decapsulated.

% subsubsection vl2 (end)

% hierarchical conclusion
\subsubsection{Conclusion} \label{ssub:hierarchical-concl}


Hierarchical models of network topology is the simplest to use since most commodity hardware supports it. Minimal setup and configuration is required for these networks. At a point scalability of these networks becomes a problem. Analysis of real-world systems show that hierarchical topologies have load-balancing issues at large scales \cite{singla2012jellyfish}.


% subsubsection hierarchical-concl (end)

% subsection net-hierarchical (end)
\subsection{Recursive Model} \label{sub:net-recursive}

Network topologies involving recursive models are characteristic of their recursive nature when scaling the number of nodes on the network. They also incorporate the use of servers to perform routing between different groups of the network as each server has two or more network interfaces \cite{wang2015survey, xia2016survey}. Described here is DCell \cite{guo2008dcell} and BCube \cite{guo2009bcube}, two recursive network topologies.

% DCell
\subsubsection{DCell} \label{subp:dcell}

DCell is able to use inexpensive commodity switches to exponentially scale the number of nodes in the network. DCells are logically arranged in groups consisting of a switch and a number of servers. The switch connects to all servers in the group and each server connects to one other DCell group. If each DCell is considered a virtual node in a graph, the connecting links between each node form a complete graph. The servers and switches require more advanced configuration as servers are forwarding data to and from other DCells. The robustness achieved through the DCell topology allows a larger amount of failures to partition the network. DCell can suffer from unbalanced workloads causing congestion over certain links due to oversubscription.

% subsubsection dcell (end)


% BCube
\subsubsection{BCube} \label{subp:bcube}

Slightly differing from DCell, BCube connects different cells to each other through a switch instead of directly to the host. This topology allows one-to-all communication to be very efficient. Links are more oversubscribed than DCell, at 1:256. The downside of BCube is that expanding the network requires re-cabling the existing topology and thus changing the switch and server configuration.

% subsubsection bcube (end)

\subsubsection{Conclusion} \label{ssub:recursive-concl}



% recursive conclusion
Recursive topologies enable providers to cheaply and efficiently scale their networks compared to hierarchical networks. As more research is performed on recursive topologies it is becoming apparent that this model is not well suited for cloud computing. Particularly the fact that since servers are performing more advanced routing than in hierarchical networks the overhead involved competes with the resources given to the applications and VMs that run on the service.

% subsubsection recursive-concl (end)

% subsection net-recursive (end)
\subsection{Rack-to-Rack Model} \label{sub:net-rack}

Characterized by the lack of a switch connecting multiple ToR switches, the rack-to-rack model connects racks directly to each other to help prevent bottlenecks in higher layers \cite{wang2015survey, xia2016survey}. Jellyfish \cite{singla2012jellyfish} and Scafida \cite{gyarmati2010scafida} are both topologies that fit under the rack-to-rack model.


% Jellyfish
\subsubsection{Jellyfish} \label{subp:jellyfish}

In the Jellyfish topology, each switch has a fixed number of ports to connect to other switches and servers. All of the switches are then randomly connected with one another. The random links between switches provide the necessary incremental expansion by being able to unplug and plug back in a new random section of the network. Any server in the Jellyfish topology can reach more servers in fewer hops compared to the Fat-tree hierarchical topology.

% subsubsection jellyfish (end)

% Scafida
\subsubsection{Scafida} \label{subp:scafida}

Scafida topologies, just like Jellyfish topologies, also include randomness in it's graph. Scafida imposes an upper bound on the length of the longest path to prevent the communication time from becoming too long. Each server and switch in the network doesn't follow any order when it comes to its addressing and routing information. Because of this, the node's routing table is programmatically determined from its surrounding neighbours.


% subsubsection scafida (end)

% rack conclusion
\subsubsection{Conclusion} \label{ssub:rack-concl}


Traffic complexity can be greatly balanced in rack-to-rack models compared to hierarchical and recursive based models due to its random routes between nodes. Another benefit is the minimal modification to the existing network when expanding the topology. The robustness of the network also increases as it takes multiple failures to partition a network. Rack-to-rack networks hasn't emerged as a useful topology to cloud providers as it has a number of drawbacks: addressing and routing of a random network of switches and servers makes it harder for servers to route to and from the Internet, additionally the redundant paths and loops reduce the throughput and increases overheads on the routing tables.

% subsubsection rack-concl (end)

% subsection net-rack (end)

% Googlescale networks: \cite{singh2015jupiter} % jupiter is a clos network topology

\section{Software Defined Networks} \label{sec:sdn}

Software Defined Networks (SDN) is the virtualization of physical networks. With SDN, custom networking protocols and addressing schemes can be used. This is particularly helpful when the overhead or limitations of certain protocols are holding back network performance \cite{Jennings2015}. Technologies such as virtual LANs (VLAN) \cite{vlan} and Virtual Private Networks (VPN) \cite{vlan} predate the cloud paradigm. Both continue to exist in the majority of all layer 3 switches but are designed with the physical hardware in mind, preventing adoption in large-scale networks where greater than 4096 VLANs are required \cite{wang2015survey}. In the post-cloud world both technologies have been reinvented as Virtual Extensible Local Area Network (VXLAN) \cite{vxlan} and Network Virtualization Using Generic Routing Encapsulation (NVGRE) \cite{nvgre}, respectively.



\subsection{Architecture}

The Open Network Foundation (ONF) is a consortium consisting of multiple members of industry and academia whose purpose is to standardize and develop SDN-based technologies. Their definition best explains what SDN is: ``In the SDN architecture, the control and data planes are decoupled, network intelligence and state are logically centralized, and the underlying network infrastructure is abstracted
from the applications'' \cite{onfSDNdef}. More of their definition explains how the SDN architecture is split into three main layers, namely: the infrastructure, control, and application layers.

% infrastructure layer
\subsubsection{Infrastructure Layer}

Also known as the forwarding layer, the infrastructure layer consists of the physical infrastructure that supports the other two layers of SDN. This layer consists of physical switches, forwarding elements, and virtual switches \cite{yan2016software}. Their use is characterized by their ability to send and receive packets to their destination or another switch.


% control layer
\subsubsection{Control Layer}

Multiple pieces of software make up the control layer, also known as the control plane. Open APIs enable control and monitoring of the physical and virtual network. This layer ties together the infrastructure and application layer by defining the communication paths \cite{yan2016software}. It also interfaces laterally between different control layer mechanisms.


% application layer
\subsubsection{Application Layer}

The application layer mainly consists of the user's applications that interact with the services provided by the SDN network \cite{yan2016software}. Examples include security applications like virtual firewalls, DDoS mitigation, and intrusion detection systems, management applications like metered usage and traffic management, mobility applications such as virtual resource migration, virtualization applications such as virtual load balancers, and business applications  \cite{larsen2012architecture}.



% use in clouds
\subsection{Uses in Clouds}

SDN enables clouds to easily configure and automate the management processes for network services by decoupling the configuration from the network device and centralizing its configuration and management \cite{yan2016software}. SDN presents the new paradigm of network-as-a-service. It continues the X-as-a-service model seen in infrastructure-, platform- and software-as-a-service. With the power gained from SDN, clouds gain more control, scalability, dynamism, and management, which can result in better energy savings \cite{yen2014sdn,lin2013flow}, load balancing \cite{yen2014sdn}, monitoring \cite{yen2014sdn}, QoS \cite{akella2014quality}, performance \cite{cziva2014sdn, lin2013flow}, policy \cite{banikazemi2013meridian,akella2014quality}, and security \cite{seeber2014improving}.

Switches are not required to know of the entire network topology, as message tunnelling implemented through the control layer enables performance improvements of VLAN communications with any scale and complexity of physical network topology. Technologies such as OpenFlow, ForCES and ONE will be discussed as providers of virtual isolated multitenant networks \cite{wang2015survey}.




\subsection{SDN Standards}

Many organizations have developed and managed SDN standards and implementations. OpenFlow of the ONF, ForCES a working group of the Internet Engineering Task Force (IETF), and ONE of Cisco are all implementations of SDN with their own approaches.

% Openflow
\subsubsection{OpenFlow}

OpenFlow \cite{openflow} is commonly mentioned when SDN is discussed as it is the most popular standard of SDN. OpenFlow is an open standard which enables switches to perform flow-level control. It also consists of the OpenFlow controller, OpenFlow-enabled switch, OpenFlow protocol, and the OpenFlow channel. It was created to standardize the way switches and the control software communicate with each other. It is implemented  both in hardware on the switch and as software. Each switch operates a flow table containing routing rules for packets. Incoming packets are forwarded according to the table or if no rule exists then the control layer decides what to do with it \cite{wang2015survey}.

% ForCES
\subsubsection{ForCES}

Forwarding and Control Element Separation (ForCES) \cite{forces} is a SDN standard built into hardware and software that allow for external control, all within the same device. Control and forwarding layers are separated but kept within the same device. ForCES defines devices called Network Elements (NE) which consist of a Control Element (CE) and a Forwarding Element (FE), much like OpenFlow's switch and controller model. The ForCES protocol is used in the CEs for controlling the FE's forwarding. Much like the OpenFlow flow table, the FEs have Logical Function Blocks (LFBs) for forwarding packets. Configuration of the FEs and CEs is done externally of the NE via a FE manager and a CE manager \cite{wang2015survey}. The biggest difference from OpenFlow is the separation of control for FEs and CEs through their respective managers.


% cisco ONE
\subsubsection{ONE}

Created by Cisco, ONE \cite{ciscoone} is a resource unifying SDN standard. It's able to utilize mobile and 60 Ghz wireless networks in addition to regular physical networks. ONE is monetized to enterprises for its flexible use and application-driven customization of network devices for driving business goals, namely faster time to market and optimized resources. ONE provides APIs for its platform of agents, overlay networks, and network devices. By focusing on more of the technology stack, ONE is able to optimize SDN better than OpenFlow \cite{wang2015survey}.


% techniques - server virtu, net i/o virt, net virt, resource virt.

% virtualized infrastructure
\subsection{Virtualized Infrastructure}

Virtualization of infrastructure can come in the form of virtual servers, switches, Network Interface Cards (NICs), links, and topologies. Clouds utilize virtualized infrastructure to partition physical resources across many users and to enable fast changes in architecture \cite{wang2015survey}.

% VM, vNIC, vLink vSwitch, vNet

\subsubsection{Virtual Machine (VM)}

VMs are created by partitioning physical resources of the host server. A hypervisor performs this virtualization by translating the guest operating system's binary hardware calls to ones that run on the host. Hypervisors offer the front line integration with virtual networks through virtual NICs \cite{wang2015survey}. Examples include Xen and VMWare. Strong isolation between the other VMs and the host server is achieved at a slight performance cost. This cost has spurred development of lighter weight machine virtualization such as Kernel VMs (KVM)/containers \cite{oci,docker} where each virtual machine takes up less of the host's resources.

\subsubsection{Virtual NIC}

Through software, the hardware-based NIC can be virtualized as a virtual NIC (vNIC). Hypervisors assign vNICs to virtual machines for connecting those machines to the virtual network. To achieve this the hypervisor has to have low level access with the host operating system to be able to intercept system calls made to the physical NIC to properly translate packets between the physical and virtual NICs. This translation can affect the networking performance when there are many vNICs in use. Hardware-assisted solutions such as SR-IOV \cite{dong2012renic} are able to provide close to native speeds. Incoming packets are read and directed to the proper vNIC in silicon.



\subsubsection{Virtual Switch and Link}

Virtual switches (vSwitches) are characterized by being defined in software instead of hardware. A vSwitch would run on each hypervisor host, providing forwarding between the vNICs and the network outside of the host. vSwitches are able to copy packets of data directly from one vNIC buffer to another vNIC buffer if they reside on the same host, otherwise the vSwitch interfaces with the physical NIC. vSwitches also implement packet loss through configurable buffer sizes, emulating the same results as a physical switch. Customization of the vSwitch includes routing control with OpenFlow modules, custom layer 2 routing, and port management \cite{wang2015survey}. Open vSwitch \cite{crisan2013openvswitch}, VALE \cite{rizzo2012vale}, and Click Router \cite{wang2013clickrouter} are all technologies that provide vSwitch functionality.

Virtual links (vLinks) virtualize the physical link between two network components. They typically use tunnelling technologies such as GRE or IPSec to create links between vNIC-vNIC or vNIC-vSwitch. These tunnels provide traffic isolation as no other devices communicate on the same link.

Both vSwitches and vLinks share the common problem of memory and CPU contention when communication buffers and traffic increase in size. Since the forwarding and routing is performed in software the speed is a magnitude less than the same operations in hardware. In a positive light, the physical switch and link sees less traffic and usage because communication between VMs on the same host can occur on the host.

\subsubsection{Virtual Network}

As mentioned earlier, VLANs and VPNs predate the cloud paradigm. From the large-scale needs of clouds emerged newer virtual networking technologies which were more scalable, efficient, secure, and easier to manage \cite{wang2015survey}. VLANs enable multiple virtual networks at layer 2 of the OSI model, while sharing the same physical network. The number of virtual networks is limited to 4096 (12 bits) due to the protocol design, a constraint for large clouds. Multitenancy with VLAN is not recommended as

VXLAN \cite{vxlan} is the successor to VLANs for cloud computing environments. It performs network segmentation by tunnelling communications through MAC-in-UDP. 16 million virtual networks (24 bits) are possible due to the increase in address size. Broadcasts on the virtual network are implemented as UDP multicasts since a broadcast on the physical network is constrained to its local subnet. Newer technology is needed that supports VXLAN in layer 3 switches. Higher latency is also prevalent due to the extra overhead when forwarding packets across a far hop distance \cite{wang2015survey}.

VPNs in cloud environments are more commonly implemented using NVGRE \cite{nvgre}. NVGRE uses GRE to tunnel MAC-in-GRE. Each layer 2 network is differentiated by a 24 bit Virtual Subnet Identifier (VSID). Broadcast isolation is achieved without burdening the underlying network.

OpenContrail \cite{opencontrail} is an OpenFlow controller which provides methods to encapsulate MAC-in-UDP and MAC-in-IP for creating layer 2 and layer 3 VPNs. OpenContrail provides an high-level SDN interface for managing and automating isolated virtual networks. The number of virtual networks are limited to 4096 based on the OpenFlow header segment number.

% routing schemes - maybe







\section{Data Processing} \label{sec:data-processing}

With enormous amounts of data that is impossible to store and process on a single machine, multiple machines are needed to process data in a cost effective and timely manner. Industries such as telecommunications, manufacturing, retail, healthcare, insurance, finance, and government are taking advantage of the large streams of information that they are processing every day to derive useful business information by using data processing systems \cite{ibmbigdataindustries}. MapReduce from Google \cite{dean2008mapreduce} was the first parallel processing framework that addressed this problem and presented a solution. Their paper has spurred development of the open source Hadoop MapReduce \cite{hadoop} and its ecosystem of other big data processing frameworks.

Big data processing systems are characteristic of their horizontal scalability of nodes while almost linearly increasing performance. Simple programming APIs and query languages make it easy to interface with these systems. These systems can be categorized into a number of types based on their characteristics: batch, stream, graph, and machine learning \cite{zhang2016survey}. Batch processing caters best to processing large collections of data in batches. Stream processing prioritizes the speed at which continuously incoming data can be processed in a short time period. Graph processing parallelizes the processing of data organized in the graph model. Lastly, machine learning processing prioritizes fast convergence when finding the optimal value(s) of an objective function. This is achieved by trading fault tolerance and strong consistency for faster results.



% focus on stream/batch processing and combinations of the two

\subsection{Batch Processing} \label{sub:batch}

Batch processing is characterized by grouping data together then processing it as a whole to maximize throughput. MapReduce-based systems inherently use map and reduce operators on the data to perform the processing. Newer frameworks offer more operators and functionality such as iteration and recursion.

MapReduce is famed for its successful abstraction of running a distributed parallel program that is fault tolerant, load balanced and has a distributed data model. Graph processing, text processing, data mining, statistical machine translation, and machine learning algorithms have all been implemented using MapReduce frameworks \cite{dean2008mapreduce}. Out of all MapReduce frameworks, the open source Hadoop by Apache is the most popular and widely used.

MapReduce frameworks became popular due to many advantages. The simplicity of not requiring developers to understand distributed systems or parallel programming, as well as simple setup and configuration of the framework made it uncomplicated to use. Fault tolerance of nodes is built into the framework, thereby preventing the entire job needing to be restarted and minimizes the lost work by breaking down the job into mutliple tasks. Flexibility is achieved by not requiring any specific structure to the input data. MapReduce is designed to be independent of the underlying storage system. Files on a distributed file system, database query results, and structured input files are all interchangeable. Lastly, MapReduce is able to scale to running on thousands of nodes in a single cluster.


\subsubsection{Workflow}

The logical workflow for MapReduce jobs work as follows:
\begin{enumerate}
    \item The user's input data is partitioned into equal sized blocks and then multiple copies of each block is stored across a distributed file system on a cluster of machines to increase data redundancy and fault tolerance.
    \item MapReduce then reads the MapReduce program to determine the number of map and reduce tasks are required. The master node assigns work to the slaves that are part of the cluster. The MapReduce scheduler will try to assign tasks to the nodes which have a copy of the data partition for a task, thereby maximizing locality \footnote{Locality has been shown in \cite{ousterhout2015making} to not matter in clusters with a suitably performant network.}.
    \item Nodes which are processing map tasks will run the specified map function to create key-value pairs. Those pairs are then grouped into $r$ partitions based on the number of reduce tasks there are. The results of the map function are stored in the global file system. The master is then notified of where the locations of each partition are. The master forwards the location information to the nodes processing the reduce tasks.
    \item Nodes that are processing the reduce tasks gather the intermediate data from the map tasks and then sorts the results by the value of the key. The values will then be aggregated by the key according to the user-defined reduce function. The results of the reduce function are stored in the global file system.
    \item The master monitors for node or task failure and reschedules those tasks to any available slave node.
    \item After all tasks complete, the user program that initiated the MapReduce job will finish.
\end{enumerate}


\subsubsection{Comparison to DBMS}

Big data systems and Data Base Management Systems (DBMS) share some common characteristics. The authors of \cite{stonebreaker2010mapreduce} concluded that DBMS and MapReduce are complementary to each other. DBMSs optimize for efficiency whereas MapReduce optimize for fault tolerance and scalability.

MapReduce is slower at executing tasks than DBMS, but is able to load data into its internal storage representation much faster than DBMS systems \cite{pavlo2009mapreduce}. The necessary overhead of Hadoop results in a slower start up time. Additionally, DBMS may organize their data in memory and disk where MapReduce doesn't change the data layout at all. DBMS have existed for decades which have brought performance improvements through methods such as column storage, compression, and parallel algorithms. In its defense, MapReduce is still in its infancy and has not had enough time to mature.

DBMS use indexes and schemas for speeding up queries and automatically performing optimizations, for example, using data types on columns to enable efficient comparison of data. Higher level abstractions are put into place where users can declaratively write queries to the schema and get data in return. MapReduce has no concept of schemas or indexes therefore the programmer is left to writing how to parse the input and implement their own optimizations. Simple operations such as selection and projection are not included and result in possibly suboptimal and difficult to reuse.

MapReduce excels at problems where complex analysis is required. An example being where map tasks are too difficult to express in SQL queries such as text analysis. One-off analysis of data is also preferential in MapReduce since it is quicker to use as there is no schema to define and the data load time is generally faster.


% TODO other batch processing frameworks
% general purpose and sql-like



% subsection batch (end)
\subsection{Stream Processing} \label{sub:stream}

% \cite{zhang2016survey}

The use cases for stream processing differ from batch processing in that stream processing caters to processing high rates of incoming data at near real-time speeds. The long latency between updates for batch processing can be too slow for some applications. Both Storm and S4 are discussed as stream processing systems.

\subsubsection{Storm}

Originally developed by Twitter, Storm \cite{toshniwal2014storm} is a distributed unbounded stream processing system. It is now an open source project of the Apache Software Foundation. Twitter's use cases involved real-time processing of hundreds of millions of user's tweets per day. Batch processing of tweets could not keep up with the volume of incoming data and realtime requirements.

Storm's architecture consists of an incoming stream of tuples which are processed individually. A topology is the name for the directed graph that contains the steps for processing the tuples. Two kinds of vertices exist: tuples flow into the graph from \textit{spouts} and \textit{bolts} are where a given function occurs. Edges represent the flow of data from a \textit{spout} to a \textit{bolt} or a \textit{bolt} to \textit{bolt}. Cycles are possible within a topology.

Storm is architected into three types of nodes: the Nimbus, workers and ZooKeeper. Nimbus is the master node and is therefore responsible for coordinating the worker nodes to act as parts of the topology. Worker nodes run the \textit{spouts} and \textit{bolts} as well as receive orders from Nimbus. ZooKeeper is responsible for keeping the state of the cluster in case of failure and providing distributed synchronizaiton.

Storm guarantees that tuples will be processed at least once and will only replay tuples in the case of failure. A backflow mechanism relays information to the originating \textit{spout} to notify it of it's progress. Trident, included with Storm, enables only once processing semantics by providing a higher level abstraction over Storm's. Trident also provides windowing, aggregation and state management which is not available in Storm.



\subsubsection{S4}

S4 \cite{neumeyer2010s4} is a distributed and decentralized architecture which takes design decisions from the Actor model and MapReduce. Streams of data are structured as events that look like $(K, A)$, where $K$ is a key consisting of a tuple and $A$ is an attribute to that key. For example, a word count program could have an event structure such as $(word, count)$.

Applications built on top of S4 consist of a graph of Processing Elements (PE). Each processing element is a function written by a programmer. Streams interconnect the PEs. The key of each event determines which node an event goes to. External streams exist where events can be sent and recieved from external applications.

PEs run on logical nodes called Processing Nodes (PN). Each PN is mapped at runtime to a physical node by the communication layer. The PNs are in charge of receiving events, executing the respective PEs on the events, and sending out new events. The communication layer is managed by ZooKeeper to maintain configuration information and coordinate between nodes of the system. Besides mapping PNs to physical nodes the communication layer generally manages the cluster and handles failures.



\subsection{Graph Processing}

Graph processing is a specialization on the data model for MapReduce jobs. GraphLab and Pregel both offer optimizations for processing large graphs of data in parallel. Some machine learning problems define their domain in the form of a graph of dependencies, therefore it is fluid to use graph processing systems to solve those kinds of problems.

\cite{zhang2016survey,low2012graphlab,malewicz2010pregel}

\subsubsection{GraphLab}

Graphs in GraphLab use the vertex-centric model where operations are performed on vertexes. GraphLab uses concepts such as a data graph, a sync mechanism, and an update function. The data graph contains the user-defined data for vertices and edges, intermediate data used by the graph algorithm, model parameters, and statistical data. The sync mechanism is used to perform aggregate calculations over the entire graph. It is analogous to the reduce function in MapReduce, but can run concurrently with the update functions. Update functions are analogous to the map part of MapReduce, but in addition to modify its own data, update functions are permitted to modify data of adjacent edges and nodes. The output of the update functions is the updated data and the vertices that need to be modified in the next iteration round.

Work is broken down into iterations where an update function or a sync mechanism operates at most once on a vertice. GraphLab synchronizes iterations between all nodes and coordinates updates between partitions. Data is partitioned across the cluster using either domain specific knowledge or partition heuristics.

Depending on the style of algorithm executed, different schedulers for running the update functions and sync mechanisms for an iteration is required. Jacobi style algorithms can use the synchronous scheduler, where all vertices are updated at the same time, or for Gauss-Seidel algorithms, a round robin scheduler can be used.

Fault tolerance is designed into GraphLab by a transparent checkpointing system that can incrementally create snapshots across the cluster. Execution is not suspended while this is occuring. When a failure occurs GraphLab will resume from the last snapshot.



\subsubsection{Pregel}




\subsection{Machine Learning Processing}

\cite{zhang2016survey,xing2015petuum}

\subsubsection{Petuum}




\section{Hadoop} \label{sec:hadoop}

\cite{zhang2016survey,polato2014hadoop,sakr2013hadoop}
% zhang2016 - 55,57,72,73

\section{Security} \label{sec:security}

\cite{liu2015survey,kazim2015survey,kalpana2015brief}



\section{Scheduling} \label{sec:scheduling}

There is no one size fits all scheduler for properly scheduling jobs to their resources. Many parameters exist which may be more important to a provider or a user of the system. The most prominent of those QoS parameters are cost, time and energy \cite{Singh2016}. Resource scheduling algorithms (RSA) can be classified into three major groups: static, dynamic and distributed. Static refers to algorithms that schedule resources before runtime whereas dynamic assigns resources at runtime. A third resource scheduling policy, distributed, is the act of scheduling resources at runtime for different environments.

%Monitoring of the entire infrastructure is required to be able to plan and react quickly to changes in demand. Both Cloud Users and Cloud Providers have to do so according to their objectives.

Cloud Providers typically have to balance their resources according to current demand as well as having enough resources for future demand. To meet demand for the future, a predictive model based on historical observations is usually used \cite{Jennings2015}.

\subsection{Algorithms} \label{sub:schedalgorithms}

A number of resource scheduling algorithm (RSA) types have been researched thus far \cite{Singh2016}:
\begin{itemize}
    \item Cost
    \item Time
    \item Energy
    \item Dynamic
    \item Priority
    \item Optimization
    \item SLA and QoS
    \item Compromised Cost Time
    \item Profit Based
    \item Hybrid
    \item Bargaining
    \item Virtual Machines
    \item Nature Inspired and Bio-Inspired
\end{itemize}



\subsubsection{Cost} \label{ssub:algCost}

% taxonomy
Cost based RSAs consist of the following subtypes: bag of tasks, hybrid, SLA, task, and virtual machine (VM).
Bag of tasks consists of first come first serve scheduling based on QoS of task.
Hybrid algorithm designs try to balance the overloading and underloading of resources.
Algorithms concerned with SLAs of both the user and provider take into account their respective QoS requirements like energy, makespan or monetary cost etc.
Task-based cost algorithms group subtasks together, then that group is scheduled the needed resources.
With VM, SLAs are used to schedule resources based on violations of the SLA.

% non-provider, migrateable workloads (dynamic)
\textcite{ana2010} describes a first come first serve budget constraint resource scheduling algorithm which minimizes cost, completion time and maximizes CPU utilization. The downside is that starvation may occur, resulting in this  method being non-optimal.
\textcite{van2010cost} worked on optimizing communication, memory and CPU for non-preemptable jobs with deadline constraints in hybrid clouds.

% distributed
A genetic cost-based algorithm that takes into account the SLA was built by \textcite{liu2013cost}. It considers a low and high budget to effectively schedule resources, ultimately lowering the SLA violations, increasing utilization and profit while lowering cost.
\textcite{su2013cost} used a DAG to map tasks with rules to map the most cost-effective resources using Pareto dominance, and another to deprioritize low priority tasks to minimize monetary cost. All of this lead to reducing makespan and monetary cost.
\textcite{ioannis2011cost} determined a way to handle starvation and migrations of performance-based VMs while focusing on the evaluation of Gang scheduling. A deadline based priority queue is used to determine the workload's priority and prevent starvation.


% subsubsection algCost (end)
% subsection schedalgorithms (end)

\subsection{QoS Parameters} \label{sub:schedQosParams}

QoS has many unique parameters that have been explored before. Based on requirements the following QoS parameters have been explored, in order of focus in research papers by Singh \cite{Singh2016}:
\begin{itemize}
    \item Cost
    \item Energy
    \item Execution Time
    \item Response Time
    \item Resource Utilization
    \item Deadline
    \item Throughput
    \item Availability
    \item Scalability
    \item Migration Cost
\end{itemize}

Will expand on each QoS parameter.

% subsection schedQosParams (end)
\subsection{Algorithm Classification} \label{sub:algclassification}


% May not want this section if not making a table
Resource scheduling algorithms can be described by a common set of characteristics as defined by \textcite{Singh2016}. Those characteristics being sub type, searching mechanism, application type, optimality, operational environment, objective function, scheduling criteria, resource scheduling strategy, merits, demerits and the technology used to test.

% subsection algclassification (end)
\subsection{Algorithm Traits} \label{sub:algtraits}

Resource scheduling algorithms solve many different types of scheduling problems. Due to the breadth of problems and the many ways to solve them a number of common traits between algorithms are realized \cite{Singh2016}.

\subsubsection{Subtype} How the RSA can be further classified from it's main classification.

\subsubsection{Searching Mechanism} The method the algorithm uses to search for the best schedule to use.

\subsubsection{Application Type} This type refers to the size, shape and characteristics of the applications that the RSA will schedule resources for. For example: homogeneous/heterogeneous scientific workloads, high performance applications, scalable applications, map reduce, etc.

\subsubsection{Optimal} The objective that the RSA aims to maximize is considered optimal if the objective has been met, otherwise a non-optimal solution was used.

\subsubsection{Operational Environment} Is the environment where this algorithm can be implemented in. The environment categories used here are homogeneous, heterogeneous, distributed and dynamic.

\subsubsection{Objective Function} The purpose that drives the scheduling of resources to workloads. eg. minimizing makespan.

\subsubsection{Scheduling Criteria} The end result of the objective function, where the result can be compared to other solutions. eg. cost, energy, etc.

\subsubsection{Merits} Individual advantages that this RSA has to offer.

\subsubsection{Demerits} Individual disadvantages that come with the RSA.

\subsubsection{Technology} The technology used to implement the algorithm for testing. eg. simulators, data processing applications, etc.

\subsubsection{Number of Citations} Defines the importance and validity of the algorithm from other peers in the research community.

% subsection algtraits (end)

\subsection{Aspects of Resource Scheduling} \label{sub:schedulingaspects}

\textcite{Singh2016} broke down resource scheduling algorithms into a descriptive set of aspects. Unscheduled task groups, workflow with many instances, service and task level scheduling, multiple workflows, and group of tasks are described.



\subsubsection*{Unscheduled Task Groups}

The need to schedule new tasks at runtime may be difficult if the set of tasks is heterogeneous. Classifying each task using a model of the resource requirements built from previous tasks can provide an adequate estimate for the execution cost. The cost and performance of the system can be improved through scheduling resources based on the estimated task execution cost.

\subsubsection*{Workflow with Many Instances}

Relative applications that run on a large number of nodes are cost constrained when processing large volumes of transactional workloads. Minimizing execution cost and time make up the criteria for the RSA. Objectively balancing the resource utilization results in cost savings.

\subsubsection*{Service and Task Level Scheduling}

Local, node level scheduling of resources to workload at runtime results in cost savings from minimizing the time taken to schedule resources. Makespan, cost and CPU time are all reduced. Particularly useful in assigning tasks and services to VMs.

\subsubsection*{Multiple Workflows}

Workflows with differing QoS parameters may be dynamically scheduled, resulting in the ability for those applications or workloads to dynamically scale at runtime. This aspect's criteria consists of CPU utilization, execution time, makespan, and scheduling success.

\subsubsection*{Group of Tasks}

Large groups of tasks or applications may face conditions where the transfer of data is high, the data set is very large or the execution time is very long. Algorithms that optimize for cost can reduce the completion time and decrease the resource utilization.


% subsection schedulingaspects (end)
\subsection{User Concerns}

\cite{Jennings2015}
Likely to have their own SLA for it's end users.


\subsection{Provider Concerns} \label{provider-concerns}

% idea: SLA's/SLO's for users, see Jennings2015


Balanced load - utilization balanced across all resources of a type

fault tolerance - impact on sys performance is minimized

energy consumption minimized - resources allocated to allow for minimum energy consumption for a workload

Any of the above may be optimized in whichever matter makes the most sense for the organization \cite{Jennings2015}.




% end scheduling
\section{Conclusion} \label{sec:conclusion}


% end conclusion
\printbibliography

\end{document}
