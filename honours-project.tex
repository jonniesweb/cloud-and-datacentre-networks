
\documentclass[fullapage,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{nameref}
\usepackage{url}

\newcommand{\secref}[1]{Section \ref{#1} - \nameref{#1}}


\iffalse
 % Outline
1. clouds (services)
2. network structure (data centre network)
3. SDN
4. My own choosing
 - service discovery
5. Hadoop
6. security
7. user concerns
 - fairness
 - budget
 - deadline
 - other constraints?
8. provider concerns
 - resource management
 - energy efficiency


\fi



\title{Cloud and Datacentre Networks}
\author{Jon Simpson}
\date{Fall 2016}


\begin{document}


\begin{titlepage}
\maketitle
\end{titlepage}

\section{Introduction} \label{sec:introduction}

Cloud and datacentres are becoming larger and more advanced in the race to provide competitive services to customers. Cloud computing demand keeps increasing as businesses find that it's more affordable to have other companies manage their infrastructure. Current datacentres are continually improving their systems to make each joule of energy as efficient as possible. The distributed systems running atop these massive clusters requires high bandwidth, low-latency networks across the nodes of a cluster. Being able to optimize globally across the cloud or datacentre by a small percentage can result in large savings.

In this paper, the main topics of cloud and datacentre networking are explained with the most up to date information available.


% reference google networking paper with 100-fold increase in speed

\subsection{Contribution} \label{sub:contribution}

\subsection{Methodology} \label{sub:methodology}

% update section names
This article is a meta-survey, constructed from a number of recent surveys and new articles focused on the topics of network structures, software-defined networks, service discovery, Hadoop, security and scheduling. The main points and ideas are collected and explained then compared on their commonalities and differences. The results from the surveys are updated with newer articles that have come out since their respective publishing date.

% end subsection methodology
\subsection{Paper Organization} \label{sub:organization}

% update organization with updated sections

Cloud and datacentre networking is broken down into the following six sections:
\secref{sec:network-structure} for the physical structure of the network, \secref{sec:sdn} discusses the networking abstractions that can be built on top of the physical networks, \secref{sec:data-processing} where services are able to discover each other in a dynamic and changing environment, \secref{sec:hadoop} being one of the leading big data processing frameworks, \secref{sec:security} for the importance and new attack vectors for modern cloud and datacentre infrastructures, and lastly \secref{sec:scheduling} discusses and classifies the algorithms and workload characteristics that go in to scheduling multiple heterogeneous workloads across a pool of resources.

\subsection{Resources} \label{sub:resources}

At the bottom layer of every datacentre and cloud is the individual resources that power it. Single units of resources that when interconnected together form powerful networks of compute and storage. The compute, network and storage resources require a comparably sized power grid to keep all of the components powered.

\subsubsection{Compute} \label{ssub:compute}

Compute is the main resource consisting of memory, CPU, network interface and local I/O. Many times the service provider runs virtual machines on top of the physical machines for the consumers to use. This provides a necessary level of abstraction to separate users in a cloud computing environment \cite{Jennings2015}.

% subsubsection compute (end)
\subsubsection{Network} \label{ssub:network}

Network equipment interconnect the computing resources to allow for high speed communication between other compute resources and the internet. Communicating effectively is constrained by cost \cite{Jennings2015}. A complete graph connects every compute resource to every other compute resource but the cost of each link grows by $n$, where $n$ is the number of compute resources, also known as nodes.

The goal of interconnecting compute resources is to provide a scalable topology where ``increasing the number of ports in the network should linearly increase the bisection bandwidth'' \cite{abts2012guided}.

The most commonly used topology for datacentres is trees. Trees provide a high bisection bandwidth for all nodes connected to the same switch. Also well known is the hyper-cubes and meshes, which are more present in High Performance Computing (HPC) \cite{Jennings2015}. Another type of topology is the Clos network. % go into more detail

Software Defined Networks (SDN) is making it possible to have more flexible networks. Custom protocols and different addressing schemes can be used where a physical network would be impractical otherwise.

% subsubsection network (end)
\subsubsection{Storage} \label{ssub:storage}


% this paragraph is awkward
Public cloud providers currently offer persistent storage through virtual disks, object storage and various types of databases. Common databases that are available are of the ACID type, while a newer type of database is of the NoSQL type. These newer types of databases are more scalable but less consistent since they don't follow the ACID transactional properties. The trade-off with these two different types of databases is performance and consistency, where performance caters to availability and response time, and consistency follows the ACID transactional properties \cite{Jennings2015}.

These NoSQL database systems do well for many use cases which don't require strong consistency. A few different types available are column stores, key-value stores, document stores, and graph databases \cite{graphDB2013}. Object stores are built on top of key-value stores, where a key is used to retrieve some data or new data is uploaded and a key corresponding to that data is returned. Both Amazon \cite{dynamodb}, Google \cite{cassandra} and LinkedIn \cite{voldemort} have their own version of a key-value datastore.

% subsubsection storage (end)

\subsubsection{Power} \label{ssub:power}

Datacentres use a significant amount of the world's energy. Powering the networking, compute and storage systems as well as the ancillary systems such as cooling, power distribution and lighting.
There are four main ways to reduce power consumption for datacentres as defined by Jennings \cite{Jennings2015}. Those are: creation of lower-power usage devices for hardware energy efficiency, energy-aware resource management (See section \ref{provider-concerns} for more information), designing applications with awareness of it's energy use, and development of more efficient ancillary systems. Additionally, the climate of the location of a datacentre can aid greatly in cooling systems.

% subsubsection power (end)

% end subsection Resources
\section{Cloud Services} \label{sec:cloud-services}

% IaaS, PaaS, SaaS

Cloud computing can be broadly categorized into three major categories: Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS), and Software-as-a-Service (SaaS). Buying IaaS from a provider gives the customer the ability to not have to worry about managing the physical infrastructure. All the cloud resources that they deal with is virtualized. In PaaS, customers use and build software on top of the providers platform. The use case solved by the platform is to make it easier and faster to build scalable software. SaaS is a cloud classification where the provider manages the software and it's associated data on behalf of the customer. The customer benefits from not having to manage the software and the required infrastructure.

\subsection{Infrastructure as a Service} \label{sub:iaas}

IaaS utilizes virtualization of the hardware to make the on-demand creation, configuration and removal of computing, storage and network equipment faster than the same process using physical hardware. The providers of IaaS are able to rent their virtualized hardware to customers as needed. Basic services such as server images, storage, and resource information are provided by the IaaS provider to make management simpler for customers.

% subsection iaas (end)
\subsection{Platform as a Service} \label{ssub:paas}

PaaS builds on top of IaaS by giving the customer the ability to build and run applications on top of a platform provided by the cloud provider. PaaS leaves the management of infrastructure up to the provider, leaving the customer to only worry about their application. PaaS usually have their support multiple programming languages and provide a Source Development Kit (SDK) to customers for building their apps. A management console may be provided to manage resources, configure PaaS services and view operational information. Notable companies in this space are Heroku \cite{heroku} and Google App Engine \cite{googleappengine}.

% subsection paas (end)
\subsection{Software as a Service} \label{sub:saas}

SaaS is a piece of software that is hosted by the provider and accessed over a network by the customer. SaaS reduces the need for the customer to maintain the hardware and software required to run the software product since the provider takes care of that. General pricing models for SaaS applications follow usage per month or per-user per month. Other types of SaaS have emerged from the expanding functionality of websites. Many websites may offer feature-rich services through the user's web browser. Examples of SaaS include various social networks \cite{facebook}, business applications \cite{salesforce} and interactive websites \cite{netflix}.

% subsection saas (end)



% subsection cloud-classification (end)
\section{Network Structure} \label{sec:network-structure}

Googlescale networks: \cite{singh2015jupiter} % jupiter is a clos network topology

\section{Software Defined Networks} \label{sec:sdn}

Software Defined Networks (SDN) is the virtualization of physical networks. With SDN, custom networking protocols and addressing schemes can be used. This is particularly helpful when the TCP protocol is holding back network performance \cite{Jennings2015}.

\section{Data Processing} \label{sec:data-processing}

\section{Hadoop} \label{sec:hadoop}

\section{Security} \label{sec:security}

\section{Scheduling} \label{sec:scheduling}

There is no one size fits all scheduler for properly scheduling jobs to their resources.

Monitoring of the entire infrastructure is required to be able to plan and react quickly to changes in demand. Both Cloud Users and Cloud Providers have to do so according to their objectives.
Cloud Providers typically have to balance their resources according to current demand as well as having enough resources for future demand. To meet demand for the future, a predictive model based on historical observations is usually used \cite{Jennings2015}.

A number of resource scheduling algorithm types have been researched thus far \cite{Singh2016}:
\begin{itemize}
    \item Cost
    \item Time
    \item Dynamic
    \item Priority
    \item Energy
    \item Optimization
    \item SLA and QoS
    \item Compromised Cost Time
    \item Profit Based
    \item Hybrid
    \item Bargaining
    \item Virtual Machines
    \item Nature Inspired and Bio-Inspired
\end{itemize}

QoS has many unique parameters that have been explored before. Based on requirements the following QoS parameters have been explored, in order of focus in research papers by Singh \cite{Singh2016}:
\begin{itemize}
    \item Cost
    \item Energy
    \item Execution Time
    \item Response Time
    \item Resource Utilization
    \item Deadline
    \item Throughput
    \item Availability
    \item Scalability
    \item Migration Cost
\end{itemize}

Resource scheduling algorithms can be described by a common set of characteristics as defined by Singh \cite{Singh2016}. Those characteristics being sub type, searching mechanism, application type, optimality, operational environment, objective function, scheduling criteria, resource scheduling strategy, merits, demerits and the technology used to test.

\subsection{User Concerns}

\cite{Jennings2015}
Likely to have their own SLA for it's end users.


\subsection{Provider Concerns} \label{provider-concerns}

% idea: SLA's/SLO's for users, see Jennings2015


Balanced load - utilization balanced across all resources of a type

fault tolerance - impact on sys performance is minimized

energy consumption minimized - resources allocated to allow for minimum energy consumption for a workload

Any of the above may be optimized in whichever matter makes the most sense for the organization \cite{Jennings2015}.




% end scheduling
\section{Conclusion} \label{sec:conclusion}



\bibliographystyle{plain}
\bibliography{research}

\end{document}
