\documentclass[fullapage,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{nameref,csquotes,hyperref}
\usepackage[english]{babel}
\usepackage[backend=biber,style=numeric]{biblatex}
\urlstyle{sf}


\bibliography{research}

\newcommand{\secref}[1]{Section \ref{#1} - \emph{\nameref{#1}}}


\iffalse
 % Outline
1. clouds (services)
2. network structure (data centre network)
3. SDN
4. data processing
5. Hadoop
6. security
7. user concerns
 - fairness
 - budget
 - deadline
 - other constraints?
8. provider concerns
 - resource management
 - energy efficiency


\fi



\title{Cloud and Datacentre Networks}
\author{Jon Simpson}
\date{Fall 2016}


\begin{document}


\begin{titlepage}
\maketitle
\thispagestyle{empty}
\end{titlepage}

\section{Introduction} \label{sec:introduction}

Cloud and datacentres are becoming larger and more advanced in the race to provide competitive services to customers. Cloud computing demand keeps increasing as businesses find that it's more affordable to have other companies manage their infrastructure. Current datacentres are continually improving their systems to make each joule of energy as efficient as possible. The distributed systems running atop these massive clusters requires high bandwidth, low-latency networks across the nodes of a cluster. Being able to optimize globally across the cloud or datacentre by a small percentage can result in large savings.

In this paper, the main topics of cloud and datacentre networking are explained with the most up to date information available.


% reference google networking paper with 100-fold increase in speed

\subsection{Contribution} \label{sub:contribution}

\subsection{Methodology} \label{sub:methodology}

% update section names
This article is a meta-survey, constructed from a number of recent surveys and new articles focused on the topics of cloud services, network structures, software defined networks, data processing, Hadoop, security and scheduling. The main points and ideas are collected and explained then compared for their commonalities and differences. The information collected from the surveys are updated with newer articles that have come out since their respective publishing date.

% end subsection methodology
\subsection{Paper Organization} \label{sub:organization}

% update organization with updated sections

Cloud and datacentre networking is broken down into the following seven sections:
\secref{sec:cloud-services} breaks down the different types of services offered by cloud providers, \secref{sec:network-structure} shows different strategies of defining the physical structure of the datacentre network, \secref{sec:sdn} discusses the virtual networking abstractions that can be built on top of the physical networks, \secref{sec:data-processing} is where batch and stream processing of data is explained, \secref{sec:hadoop} being one of the leading big data processing frameworks, \secref{sec:security} for the importance and new attack vectors for modern cloud and datacentre infrastructures, and lastly \secref{sec:scheduling} discusses and classifies the algorithms and workload characteristics that go in to assigning resources to workloads.

\subsection{Resources} \label{sub:resources}

At the bottom layer of every datacentre and cloud is the individual resources that power it. Single units of resources that when interconnected together form powerful networks of compute and storage. The compute, network and storage resources require a comparably sized power grid to keep all of the components powered.

\subsubsection{Compute} \label{ssub:compute}

Compute is the main resource consisting of memory, CPU, network interface and local I/O. Many times the service provider runs virtual machines on top of the physical machines for the consumers to use. This provides a necessary level of abstraction to separate users in a cloud computing environment \cite{Jennings2015}.

% subsubsection compute (end)
\subsubsection{Network} \label{ssub:network}

Network equipment interconnect the computing resources to allow for high speed communication between other compute resources and the internet. Communicating effectively is constrained by cost \cite{Jennings2015}. A complete graph connects every compute resource to every other compute resource but the cost of each link grows by $n$, where $n$ is the number of compute resources, also known as nodes.

The goal of interconnecting compute resources is to provide a scalable topology where ``increasing the number of ports in the network should linearly increase the bisection bandwidth'' \cite{abts2012guided}.

The most commonly used topology for datacentres is trees. Trees provide a high bisection bandwidth for all nodes connected to the same switch. Also well known is the hyper-cubes and meshes, which are more present in High Performance Computing (HPC) \cite{Jennings2015}. Another type of topology is the Clos network. % go into more detail

Software Defined Networks (SDN) is making it possible to have more flexible networks. Custom protocols and different addressing schemes can be used where a physical network would be impractical otherwise.

% subsubsection network (end)
\subsubsection{Storage} \label{ssub:storage}


% this paragraph is awkward
Public cloud providers currently offer persistent storage through virtual disks, object storage and various types of databases. Common databases that are available are of the ACID type, while a newer type of database is of the NoSQL type. These newer types of databases are more scalable but less consistent since they don't follow the ACID transactional properties. The trade-off with these two different types of databases is performance and consistency, where performance caters to availability and response time, and consistency follows the ACID transactional properties \cite{Jennings2015}.

These NoSQL database systems do well for many use cases which don't require strong consistency. A few different types available are column stores, key-value stores, document stores, and graph databases \cite{graphDB2013}. Object stores are built on top of key-value stores, where a key is used to retrieve some data or new data is uploaded and a key corresponding to that data is returned. Both Amazon \cite{dynamodb}, Google \cite{cassandra} and LinkedIn \cite{voldemort} have their own version of a key-value datastore.

% subsubsection storage (end)

\subsubsection{Power} \label{ssub:power}

Datacentres use a significant amount of the world's energy. Powering the networking, compute and storage systems as well as the ancillary systems such as cooling, power distribution and lighting.
There are four main ways to reduce power consumption for datacentres as defined by Jennings \cite{Jennings2015}. Those are: creation of lower-power usage devices for hardware energy efficiency, energy-aware resource management (see section \ref{provider-concerns} for more information), designing applications with awareness of it's energy use, and development of more efficient ancillary systems. Additionally, the climate of the location of a datacentre can aid greatly in cooling systems \cite{norwaydatacentre}.

% subsubsection power (end)

% end subsection Resources
\section{Cloud Services} \label{sec:cloud-services}

The definition of cloud services (also known as cloud computing) is best described by the National Institute of Standards and Technology (NIST):

\begin{displayquote}
Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. This cloud model is composed of five essential characteristics, three service models, and four deployment models \cite{mell2011nist}.
\end{displayquote}

In the next three sections the essential characteristics, service models, and deployment models are explained.


% future subsection: taxonomy (2009) - cloud architecture, virtualization management, service (iaas,paas, etc), fault tolerance, security

\subsection{Essential Characteristics} \label{sub:essential-characteristics}
% Essential characteristics - on-demand self service, broad network access, resource pooling, rapid elasticity, measured service

Cloud computing can be characterized by the five distinct characteristics that separate it from traditional computing. Those five characteristics are on-demand self service, broad network access, resource pooling, rapid elasticity, and measured service \cite{alam2015comprehensive, dillon2010cloud}.

\subsubsection{On-Demand Self Service} \label{ssub:on-demand}

Consumers are able to request and receive computing resources at any time from the service provider without having to interact with a human. This means that humans and other systems are able to automatically obtain and release computing resources depending on their needs.


% subsubsection on-demand (end)
\subsubsection{Broad Network Access} \label{ssub:net-access}

Customers of the consumer are able to access and interact with the computing resources over a network, such as the Internet. Heterogeneous customers are all able to access the resources if they are able to access the network.


% subsubsection net-access (end)
\subsubsection{Resource Pooling} \label{ssub:resource-pooling}

Resources of the provider are pooled together such that the consumer is unaware of the underlying organization of the physical hardware. The resource pooling is achieved either through multi-tenancy or virtualization of the computing resources. This enables flexibility for the provider as they are able to flexibly grow or shrink their physical infrastructure without affecting the consumer's resource allocations. Consumers also benefit by being able to dynamically change their resource allocations and not have to worry about the placement of those resources.


% subsubsection resource-pooling (end)
\subsubsection{Rapid Elasticity} \label{ssub:elasticity}

Consumers of the cloud service are able to change their resource allocation at any time without any prior commitment or contracts. The maximum amount of resources that can be allocated should appear to be infinite to the consumer. Consumers are freely able to scale up and scale down resource allocation according to their needs.


% subsubsection elasticity (end)
\subsubsection{Measured Service} \label{ssub:measured-service}

Pooled resources that are shared among many consumers (possibly multiple consumers sharing the same physical hardware) are able to be measured by other cloud infrastructure. The provider may simply track it for driving business decisions or additionally use this information to bill the consumer.


% subsubsection measured-service (end)

% subsection essential-characteristics (end)
\subsection{Service Models} \label{sub:servicemodels}

Cloud services can be broadly categorized into three major categories:\linebreak Infrastructure-as-a-Service (IaaS), Platform-as-a-Service (PaaS), and\linebreak Software-as-a-Service (SaaS). Buying IaaS from a provider gives the customer the ability to not have to worry about managing the physical infrastructure. All the cloud resources that they deal with is virtualized. In PaaS, customers use and build software on top of the providers platform. The use case solved by the platform is to make it easier and faster to build scalable software without having to worry about the underlying infrastructure. SaaS is a cloud classification where the provider manages the software, it's associated data and the infrastructure it uses on behalf of the customer. The customer benefits by being able to use the service without having to deal with running and maintaining the infrastructure \cite{Manvi2014}.

\subsubsection{Infrastructure as a Service} \label{ssub:iaas}

IaaS utilizes virtualization of the hardware to make the on-demand creation, configuration and removal of computing, storage and network equipment faster than the same process using physical hardware. The providers of IaaS are able to rent their virtualized hardware to customers as needed. Basic services such as server images, storage, and resource information are provided by the IaaS provider to make management simpler for customers.

% subsubsection iaas (end)
\subsubsection{Platform as a Service} \label{ssub:paas}

PaaS builds on top of IaaS by giving the customer the ability to build and run applications on top of a platform provided by the cloud provider. PaaS leaves the management of infrastructure up to the provider, leaving the customer to only worry about their application. PaaS usually have their support multiple programming languages and provide a Source Development Kit (SDK) to customers for building their apps. A management console may be provided to manage resources, configure PaaS services and view operational information. Notable companies in this space are Heroku \cite{heroku} and Google App Engine \cite{googleappengine}.

% subsubsection paas (end)
\subsubsection{Software as a Service} \label{ssub:saas}

SaaS is a piece of software that is hosted by the provider and accessed over a network by the customer. SaaS reduces the need for the customer to maintain the hardware and software required to run the software product since the provider takes care of that. General pricing models for SaaS applications follow usage per month or per-user per month. Other types of SaaS have emerged from the expanding functionality of websites. Many websites may offer feature-rich services through the user's web browser. Examples of SaaS include various social networks \cite{facebook}, business applications \cite{salesforce} and interactive websites \cite{netflix}.

% subsubsection saas (end)


% subsection servicemodels (end)
\subsection{Deployment Models} \label{sub:deployment-model}
% deployment model - public,private, community, hybrid

Orthogonal to the \nameref{sub:servicemodels} section is the deployment model. Different types of cloud services can be deployed in different scenarios based on policy, ownership, cost, and security. To the customer of the consumer, the deployment model of the cloud service is completely transparent.

\subsubsection{Public} \label{ssub:deploy-public}

The most prominent type of cloud deployment is the public cloud. Public clouds enable any person or organization to use computing resources. The cloud provider is usually an organization which in charge of the cloud's availability, policies, billing models and operation.


% subsubsection deploy-public (end)
\subsubsection{Private} \label{ssub:deploy-private}

Many different types of organizations would consider to run a private cloud. These clouds are either operated by the organization or a third party on behalf of the organization. Organizations and enterprises run their own private cloud if they have sensitive data or mission critical services that require full control over the entire computing stack, to maximize the utilization of their current computing resources, or if it's not economical to send large amounts of data off premise to a computing provider. Additionally, researchers may also build their own for their research and teaching.


% subsubsection deploy-private (end)
\subsubsection{Community} \label{ssub:deploy-community}

A group of organizations contribute to the building and management of a cloud infrastructure. Policies and other rules are decided by the group. Each organization would get a proportion of the computing resources according to their agreement. The cloud could be hosted remotely or in the premises of one of the organizations.



% subsubsection deploy-community (end)
\subsubsection{Hybrid} \label{ssub:deploy-hybrid}

Public-private, private-community, public-community, and public-private-community are all combinations of hybrid clouds. Hybrid clouds require the ability to seamlessly move workloads and data from one cloud to another. If free computing resources is reaching it's maximum on a private cloud, a public cloud can be used to provide extra resources. This is called ``cloud bursting'' as it can provide extra computing resources when the organization's own computing resources are in peak demand \cite{dillon2010cloud}.


% subsubsection deploy-hybrid (end)

% subsection deployment-model (end)

% section cloud-services (end)
\section{Network Structure} \label{sec:network-structure}

Cloud and datacentres require an interconnect for servers to communicate with each other and for providing service to consumers on the Internet. Many different types of structures are possible but all offer their benefits and weaknesses. Described next are the features of network topologies, then the different network topology types themselves.


\subsection{Topology Features} \label{sub:topology-features}

Network topologies come in many different shapes and sizes. Based on the cloud or datacentre's use cases and the organization's budget some topologies are better than others. The following features break down the different network structures available. Those features are: parallel traffic, bandwidth oversubscription, backwards capability, scalability, automatic renaming, robustness, and load balance.


\subsubsection{Parallel Traffic} \label{ssub:parallel-traffic}

Workloads which require different types of communication such as one-to-all, one-to-many, or all-to-all should be taken into consideration as the bandwidth required for these communication styles can be high depending on the number of servers processing the workload. An example of the all-to-all communication style would be the Hadoop MapReduce shuffle phase, where data is transferred from the map task running on many servers to the reduce stage which also runs on many servers.

% subsubsection parallel-traffic (end)
\subsubsection{Bandwidth Oversubscription} \label{ssub:bandwidth-oversubscription}

The more servers that are connected with each other the more expensive it is to provide a full bisection bandwidth. Topology design then cost are the main drivers of bisection bandwidth.  Bandwidth oversubscription occurs when the network topology doesn't provide full bandwidth bisection. The oversubscription can be expressed as a ratio for quantitative comparison. Some providers may choose a topology which performs bandwidth oversubscription on the premise that the network bandwidth will not be the bottleneck resource.


% subsubsection bandwidth-oversubscription (end)
\subsubsection{Backwards Capability} \label{ssub:backwards-capability}

The ability to communicate in one direction should be possible and as performant in the other direction as well. An example would be workloads which require two servers being able to use their full bisection bandwidth in both directions to communicate with each other.


% subsubsection backwards-capability (end)
\subsubsection{Scalability} \label{ssub:net-scalability}

As cloud and datacentre computing demand grows, so does the ability to scale existing computing resources and the networks that interconnect them. The ease at which adding on or removing from an existing network is defined as the scalability. Two important factors with scaling is the ability to interconnect servers on the order of thousands together, as well as the possibility of expanding the network size in the future without requiring substantial reorganization of the existing network.


% subsubsection net-scalability (end)
\subsubsection{Automatic Renaming} \label{ssub:auto-renaming}

Each switch and node in the network should automatically be able to determine where it is and setup its routing table respective to its adjacent nodes, whether that is other servers or switches. This is opposite to offline configuration, where a human or program configures the routing information for each switch and node in the network.


% subsubsection auto-renaming (end)
\subsubsection{Robustness} \label{ssub:net-robustness}

A topology should provide a way to route traffic around a failed switch or link. The more robust a network topology is the more failure it can tolerate before part of it becomes unavailable. Redundant paths in the network increase the robustness by providing an additional way for communication to occur between servers in the network.


% subsubsection net-robustness (end)
\subsubsection{Load Balance} \label{ssub:net-load-balance}

The design of the topology should take into account where bottlenecks could occur because this could lead to performance problems such as congestion. Congestion can occur at the bottleneck from too much data being sent in to the switch and there being not enough bandwidth to send back out. The switch would either slow down the consumption of incoming data or drop input data entirely. The result of congestion is increased latency and communication timeouts. In workloads with high data exchange it may be important to have a stable latency in presence of high bandwidth usage across the network.


% subsubsection net-load-balance (end)

% subsection topology-features (end)
\subsection{Network Topologies} \label{sub:net-topologies}

Current network topologies can be grouped into three main types: hierarchical, recursive and rack-to-rack. Each type share a similar number of features and topology layout.


\subsubsection{Hierarchical Model} \label{sub:net-hierarchical}

Hierarchical models are the most commonly used since they offer simple deployment and straightforward comprehension of the multiple layers that comprise it. Each layer in a hierarchical network treats traffic differently. Congestion is reduced from the lower layers by sending data through the upper layers, which are better suited to route traffic from point-to-point.

\subparagraph{Three-tier} \label{subp:three-tier}

One of the most common hierarchical models is the three-tier hierarchical topology. It consists of the core, aggregation and edge layers, where the edge layer is the layer directly connected to the servers (also known as the top of rack switch (ToR)), the aggregation layer which interfaces between the edge layer and the core layer, and the core layer directly connects to the Internet as well as to every aggregation layer. This layout enables the addition or removal of edge switches and aggregation switches with the minimal amount of modification to the existing network.
% subparagraph three-tier (end)

\subparagraph{Fat-tree} \label{subp:fat-tree}

The Fat-tree hierarchical network structure takes the existing three-tier topology and groups together aggregated switches with it's associated edge switches to form pods. These pods are then connected to the core layer switches for performing communication between the Internet and the pods. All switches in all three layers are identical commodity switches. At each higher layer the number of switches increases to provide full end-to-end bisection bandwidth. Another benefit is that there exists multiple equal-cost paths for communication to occur between any two hosts. The downside to Fat-trees is that the cabling complexity is large due to obtaining the full bisection bandwidth.
% subparagraph fat-tree (end)

% VL2
\subparagraph{VL2} \label{subp:vl2}

% subparagraph vl2 (end)

% hierarchical conclusion



% subsubsection net-hierarchical (end)
\subsubsection{Recursive Model} \label{sub:net-recursive}

% DCell
\subparagraph{DCell} \label{subp:dcell}

% subparagraph dcell (end)


% BCube
\subparagraph{BCube} \label{subp:bcube}

% subparagraph bcube (end)

% recursive conclusion


% subsubsection net-recursive (end)
\subsubsection{Rack-to-Rack Model} \label{sub:net-rack}

% Jellyfish
\subparagraph{Jellyfish} \label{subp:jellyfish}

% subparagraph jellyfish (end)

% Scafida
\subparagraph{Scafida} \label{subp:scafida}


% subparagraph scafida (end)

% rack conclusion




% subsubsection net-rack (end)
% subsection net-topologies (end)

Googlescale networks: \cite{singh2015jupiter} % jupiter is a clos network topology

\section{Software Defined Networks} \label{sec:sdn}

Software Defined Networks (SDN) is the virtualization of physical networks. With SDN, custom networking protocols and addressing schemes can be used. This is particularly helpful when the overhead or limitations of certain protocols are holding back network performance \cite{Jennings2015}.

\section{Data Processing} \label{sec:data-processing}

% focus on stream/batch processing and combinations of the two

\subsection{Batch Processing} \label{sub:batch}


% subsection batch (end)
\subsection{Stream Processing} \label{sub:stream}

\subsection{DataFlow} \label{sub:dataflow}

% subsection dataflow (end)
% subsection stream (end)
% section data processing (end)
\section{Hadoop} \label{sec:hadoop}

\section{Security} \label{sec:security}

\cite{liu2015survey}

\section{Scheduling} \label{sec:scheduling}

There is no one size fits all scheduler for properly scheduling jobs to their resources. Many parameters exist which may be more important to a provider or a user of the system. The most prominent of those QoS parameters are cost, time and energy \cite{Singh2016}. Resource scheduling algorithms (RSA) can be classified into three major groups: static, dynamic and distributed. Static refers to algorithms that schedule resources before runtime whereas dynamic assigns resources at runtime. A third resource scheduling policy, distributed, is the act of scheduling resources at runtime for different environments.

%Monitoring of the entire infrastructure is required to be able to plan and react quickly to changes in demand. Both Cloud Users and Cloud Providers have to do so according to their objectives.

Cloud Providers typically have to balance their resources according to current demand as well as having enough resources for future demand. To meet demand for the future, a predictive model based on historical observations is usually used \cite{Jennings2015}.

\subsection{Algorithms} \label{sub:schedalgorithms}

A number of resource scheduling algorithm (RSA) types have been researched thus far \cite{Singh2016}:
\begin{itemize}
    \item Cost
    \item Time
    \item Energy
    \item Dynamic
    \item Priority
    \item Optimization
    \item SLA and QoS
    \item Compromised Cost Time
    \item Profit Based
    \item Hybrid
    \item Bargaining
    \item Virtual Machines
    \item Nature Inspired and Bio-Inspired
\end{itemize}



\subsubsection{Cost} \label{ssub:algCost}

% taxonomy
Cost based RSAs consist of the following subtypes: bag of tasks, hybrid, SLA, task, and virtual machine (VM).
Bag of tasks consists of first come first serve scheduling based on QoS of task.
Hybrid algorithm designs try to balance the overloading and underloading of resources.
Algorithms concerned with SLAs of both the user and provider take into account their respective QoS requirements like energy, makespan or monetary cost etc.
Task-based cost algorithms group subtasks together, then that group is scheduled the needed resources.
With VM, SLAs are used to schedule resources based on violations of the SLA.

% non-provider, migrateable workloads (dynamic)
\textcite{ana2010} describes a first come first serve budget constraint resource scheduling algorithm which minimizes cost, completion time and maximizes CPU utilization. The downside is that starvation may occur, resulting in this  method being non-optimal.
\textcite{van2010cost} worked on optimizing communication, memory and CPU for non-preemptable jobs with deadline constraints in hybrid clouds.

% distributed
A genetic cost-based algorithm that takes into account the SLA was built by \textcite{liu2013cost}. It considers a low and high budget to effectively schedule resources, ultimately lowering the SLA violations, increasing utilization and profit while lowering cost.
\textcite{su2013cost} used a DAG to map tasks with rules to map the most cost-effective resources using Pareto dominance, and another to deprioritize low priority tasks to minimize monetary cost. All of this lead to reducing makespan and monetary cost.
\textcite{ioannis2011cost} determined a way to handle starvation and migrations of performance-based VMs while focusing on the evaluation of Gang scheduling. A deadline based priority queue is used to determine the workload's priority and prevent starvation.


% subsubsection algCost (end)
% subsection schedalgorithms (end)

\subsection{QoS Parameters} \label{sub:schedQosParams}

QoS has many unique parameters that have been explored before. Based on requirements the following QoS parameters have been explored, in order of focus in research papers by Singh \cite{Singh2016}:
\begin{itemize}
    \item Cost
    \item Energy
    \item Execution Time
    \item Response Time
    \item Resource Utilization
    \item Deadline
    \item Throughput
    \item Availability
    \item Scalability
    \item Migration Cost
\end{itemize}

Will expand on each QoS parameter.

% subsection schedQosParams (end)
\subsection{Algorithm Classification} \label{sub:algclassification}


% May not want this section if not making a table
Resource scheduling algorithms can be described by a common set of characteristics as defined by \textcite{Singh2016}. Those characteristics being sub type, searching mechanism, application type, optimality, operational environment, objective function, scheduling criteria, resource scheduling strategy, merits, demerits and the technology used to test.

% subsection algclassification (end)
\subsection{Algorithm Traits} \label{sub:algtraits}

Resource scheduling algorithms solve many different types of scheduling problems. Due to the breadth of problems and the many ways to solve them a number of common traits between algorithms are realized \cite{Singh2016}.

\subsubsection*{Subtype} How the RSA can be further classified from it's main classification.

\subsubsection*{Searching Mechanism} The method the algorithm uses to search for the best schedule to use.

\subsubsection*{Application Type} This type refers to the size, shape and characteristics of the applications that the RSA will schedule resources for. For example: homogeneous/heterogeneous scientific workloads, high performance applications, scalable applications, map reduce, etc.

\subsubsection*{Optimal} The objective that the RSA aims to maximize is considered optimal if the objective has been met, otherwise a non-optimal solution was used.

\subsubsection*{Operational Environment} Is the environment where this algorithm can be implemented in. The environment categories used here are homogeneous, heterogeneous, distributed and dynamic.

\subsubsection*{Objective Function} The purpose that drives the scheduling of resources to workloads. eg. minimizing makespan.

\subsubsection*{Scheduling Criteria} The end result of the objective function, where the result can be compared to other solutions. eg. cost, energy, etc.

\subsubsection*{Merits} Individual advantages that this RSA has to offer.

\subsubsection*{Demerits} Individual disadvantages that come with the RSA.

\subsubsection*{Technology} The technology used to implement the algorithm for testing. eg. simulators, data processing applications, etc.

\subsubsection*{Number of Citations} Defines the importance and validity of the algorithm from other peers in the research community.

% subsection algtraits (end)

\subsection{Aspects of Resource Scheduling} \label{sub:schedulingaspects}

\textcite{Singh2016} broke down resource scheduling algorithms into a descriptive set of aspects. Unscheduled task groups, workflow with many instances, service and task level scheduling, multiple workflows, and group of tasks are described.



\subsubsection*{Unscheduled Task Groups}

The need to schedule new tasks at runtime may be difficult if the set of tasks is heterogeneous. Classifying each task using a model of the resource requirements built from previous tasks can provide an adequate estimate for the execution cost. The cost and performance of the system can be improved through scheduling resources based on the estimated task execution cost.

\subsubsection*{Workflow with Many Instances}

Relative applications that run on a large number of nodes are cost constrained when processing large volumes of transactional workloads. Minimizing execution cost and time make up the criteria for the RSA. Objectively balancing the resource utilization results in cost savings.

\subsubsection*{Service and Task Level Scheduling}

Local, node level scheduling of resources to workload at runtime results in cost savings from minimizing the time taken to schedule resources. Makespan, cost and CPU time are all reduced. Particularly useful in assigning tasks and services to VMs.

\subsubsection*{Multiple Workflows}

Workflows with differing QoS parameters may be dynamically scheduled, resulting in the ability for those applications or workloads to dynamically scale at runtime. This aspect's criteria consists of CPU utilization, execution time, makespan, and scheduling success.

\subsubsection*{Group of Tasks}

Large groups of tasks or applications may face conditions where the transfer of data is high, the data set is very large or the execution time is very long. Algorithms that optimize for cost can reduce the completion time and decrease the resource utilization.


% subsection schedulingaspects (end)
\subsection{User Concerns}

\cite{Jennings2015}
Likely to have their own SLA for it's end users.


\subsection{Provider Concerns} \label{provider-concerns}

% idea: SLA's/SLO's for users, see Jennings2015


Balanced load - utilization balanced across all resources of a type

fault tolerance - impact on sys performance is minimized

energy consumption minimized - resources allocated to allow for minimum energy consumption for a workload

Any of the above may be optimized in whichever matter makes the most sense for the organization \cite{Jennings2015}.




% end scheduling
\section{Conclusion} \label{sec:conclusion}


% end conclusion
\printbibliography

\end{document}
